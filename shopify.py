# -*- coding: utf-8 -*-
"""Shopify.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19EWQhmUOnBnFEUKGfi_A02Lti7eIzcFW
"""

import pandas as pd
import numpy as np
from io import StringIO
import io
from google.colab import files
uploaded = files.upload()
import matplotlib.pyplot as plt

df =  pd.read_csv(io.BytesIO(uploaded['2019 Winter Data Science Intern Challenge Data Set - Sheet1.csv']))
df

aov = df['order_amount'].mean()
print(aov)

ind = df.columns.get_loc('order_amount')
orders = df.iloc[:, [ind]]
orders
orders.boxplot(vert=False)
plt.subplots_adjust(left=0.01)
plt.show()

med = df['order_amount'].median()
print(med)

"""If we know that our naive AOV calculation is much higher than what we would expect it to be, it is reasonable to think that the data is skewed due to the prescence of outliers. By plotting our data as a scatterplot, we can confirm this, by seeing the prescence of outliers. Because AOV calculations take the average of all orders, outliers with an extremely high value can skew our averages, causing our AOV to be much higher than what we expect. 

A better way to evaluate this data would be to either remove all outliers, or to use a different metric which is not so heavily influenced by outliers.

I would use the median of all the order values (median order value) rather than the average order value. Because the median represents the midpoint of all of our values, it is less influenced by skew and outliers. Very high order values are counted the same as moderately high or even slightly high order values, making the median a more accurate representation of what we might expect a customer to spend on a shoe.

The median is 284.0
"""